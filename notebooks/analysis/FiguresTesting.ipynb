{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f2df355",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = 1/2.54\n",
    "def getparentdir(foldername):\n",
    "    import os\n",
    "    parent = \"E:\\Raphael\\Data\"\n",
    "    listdir = os.listdir(parent)\n",
    "    for d in listdir:\n",
    "        if d[0] == foldername:\n",
    "            parent = os.path.join(parent, d)\n",
    "    return parent\n",
    "\n",
    "def loadgroup(path):\n",
    "    # This function loads any csv dedicated to tell ing the algorithm what fields correspond to what condition\n",
    "    #Input: Path to a specific file that contains a map of the experiment\n",
    "    #0 = no experiment was performed in this slot -> will be deleted later\n",
    "    #None -> Condition not relevent for experiment (e.g. a well or lane that has only one condition while others have two)\n",
    "    # Output: dictionary with A1-H12 as keys containing the labels\n",
    "    import pandas as pd\n",
    "    import csv\n",
    "    import string\n",
    "    ABC = list(string.ascii_uppercase)\n",
    "    dic = {}\n",
    "    with open(path) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter = \";\")\n",
    "        i = 0\n",
    "        #loop through all wells\n",
    "        for row in reader:\n",
    "            for j in range(len(row)):\n",
    "                #find correct enumeration\n",
    "                key = ABC[i]+str(j+1) \n",
    "                #delete unwanted letters in first position\n",
    "                f = row[j].split(\"ï»¿\") \n",
    "                f = f[len(f)-1]\n",
    "                dic[key] = f\n",
    "            i = i+1\n",
    "    return(dic)\n",
    "\n",
    "def subtractbasic(dic, header):\n",
    "    #subtracts the background flourescence measured from untransfected cells from the others\n",
    "    #Input: Labeled dictionary cotaining the measured intensity by flourometry\n",
    "    #Output: Addition of \"Subtracted\" entries. These will be used afterwards\n",
    "    #Output dict also differs from input dict!!!!\n",
    "    #Input has Wells as keys\n",
    "    #Ouput will use fields (like \"Wells\", \"Mean\")\n",
    "    import pandas as pd\n",
    "    data = {}\n",
    "    #loop though whole dict and create new one\n",
    "    #new dict is organised by groups\n",
    "    for key in dic:\n",
    "        td = dic[key]\n",
    "        for k in td:\n",
    "            if k not in data:\n",
    "                data[k] = []\n",
    "            data[k].append(td[k])\n",
    "        if \"Well\" not in data:\n",
    "            data[\"Well\"] = []\n",
    "        data[\"Well\"].append(key)\n",
    "        if \"Lane\" not in data:\n",
    "            data[\"Lane\"] = []\n",
    "        data[\"Lane\"].append(key[0])\n",
    "        if \"Col\" not in data:\n",
    "            data[\"Col\"] = []\n",
    "        data[\"Col\"].append(key[1:len(key)])\n",
    "    #create dataframe to calculate median and subtract\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    base = df[header][df[\"Group1\"] == \"NT\"].median()\n",
    "    head = df.keys()\n",
    "    for i in range(len(base)):\n",
    "        \n",
    "        df[head[i]+\"_sub\"] =  pd.to_numeric(df[head[i]])-float(base[i])\n",
    "    dic = df.to_dict()\n",
    "    return dic\n",
    "\n",
    "def clearf(dic):\n",
    "    #clears dict of all unwanted entries\n",
    "    delete = [\"NT\", \"BL\", \"0\"]\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame.from_dict(dic)\n",
    "    \n",
    "    for d in delete:\n",
    "        df.drop(df.loc[df[\"Group1\"]==d].index,inplace=True)\n",
    "    dic = df.to_dict()\n",
    "    return dic\n",
    "    \n",
    "    \n",
    "def loadspark(loc):\n",
    "    #loads the excel file generated by flourometry measurement\n",
    "    #Input: Unedited xlsx file called \"Spark\"\n",
    "    #Output: Labeled dictionary; without bradford information\n",
    "    import pathophys as pp\n",
    "    import pandas as pd\n",
    "    import csv\n",
    "    import os\n",
    "    Sxlsx = os.path.join(loc,\"Spark.xlsx\")\n",
    "    Scsv = os.path.join(loc,\"Spark.csv\")\n",
    "    dic = {}\n",
    "    read_file = pd.read_excel (Sxlsx)\n",
    "    read_file.to_csv (Scsv, index = None, header=True)\n",
    "    #xlsx file is easy to open with pandas\n",
    "    #first is converted to csv then opened as such\n",
    "    with open(Scsv) as csvfile:\n",
    "            ind = 0\n",
    "            header = []\n",
    "            Wells = []\n",
    "            reader = csv.reader(csvfile)\n",
    "            for row in reader:\n",
    "                #when the correct line is reached the information is gathered\n",
    "                #This is done up to the 7th line\n",
    "                if ind in range(1,8):\n",
    "                    #The first entry denotes the kind of information written in the line\n",
    "                    M = row[0]\n",
    "                    #These are stored in the \"Header\" list\n",
    "                    header.append(M)\n",
    "                    #the fc variable tracks the index of the field in the row\n",
    "                    fc = 0\n",
    "                    for field in row:\n",
    "                        #if the reader moves past the first entry the entries get converted to floats\n",
    "                        if fc > 0 and ind > 1:\n",
    "                            dic[Wells[fc]][M] = float(field)\n",
    "                        else:\n",
    "                            dic[Wells[fc]][M] = field\n",
    "                        fc = fc+1\n",
    "                    ind = ind+1\n",
    "                #first row of results is denoted by \"Wells\"\n",
    "                #when the reader reaches this line...\n",
    "               \n",
    "                if row[0] == \"Well\": \n",
    "                    #1. a list of all wells is created\n",
    "                    Wells = row\n",
    "                    #2. for each well a dictionary is created inside the main dict\n",
    "                    for field in Wells:\n",
    "                        dic[field] = {}\n",
    "                    #the indicator is set to 1 to signal that n+the next line contains information\n",
    "                    ind = 1\n",
    "            #the entry \"Well\" is not needed (it only stores reduntant information)\n",
    "            dic.pop(\"Well\")\n",
    "    #next the overlay is loaded to give meaning to the wells\n",
    "    #files must me csv and named Groupx x being the number of the group (starting form 1)\n",
    "    for filename in os.listdir(loc):\n",
    "        if \"Group\" in filename:\n",
    "            path = os.path.join(loc,filename)\n",
    "            #The group name will be the column header of the labels\n",
    "            group = filename.split(\".\")[0]\n",
    "            #group gets loaded\n",
    "            g = pp.loadgroup(path)\n",
    "            #information is put into the original dict\n",
    "            #since both are orgnaised by wells this is used to combine them\n",
    "            for key in dic:\n",
    "                dic[key][group] = g[key]\n",
    "    #next the mean of the \"NT\" condition is subtracted from all wells\n",
    "    dic = pp.subtractbasic(dic, header)\n",
    "    #all wells not containing important information are cleared\n",
    "    dic = pp.clearf(dic)\n",
    "    return dic, header\n",
    "\n",
    "\n",
    "def loadbff(loc):\n",
    "    #loads the excel file generated by photometry measurement\n",
    "    #Input: Unedited xlsx file called \"Bradford\"\n",
    "    #Output: Labeled dictionary with bradford information\n",
    "    import pathophys as pp\n",
    "    import pandas as pd\n",
    "    import csv\n",
    "    import os\n",
    "    #similar method as described above\n",
    "    Bxlsx = os.path.join(loc,\"Bradford.xlsx\")\n",
    "    Bcsv = os.path.join(loc,\"Bradford.csv\")\n",
    "    dic = {}\n",
    "    read_file = pd.read_excel (Bxlsx)\n",
    "    read_file.to_csv (Bcsv, index = None, header=True)\n",
    "    with open(Bcsv) as csvfile:\n",
    "            ind = 0\n",
    "            reader = csv.reader(csvfile)\n",
    "            for row in reader:\n",
    "                #There are more rows to  read\n",
    "                if ind in range(1,9):\n",
    "                    L = row[0]\n",
    "                    for i in range(1,len(row)):\n",
    "                        #w is the well ID\n",
    "                        w = L+str(i)\n",
    "                        dic[w] = row[i]\n",
    "                    ind = ind+1\n",
    "                #Indicator in this cas could be either \"Abs\" or \"Signal\" depending on which export was used\n",
    "                if row[0] == \"Abs\" or row[0] == \"Signal\":\n",
    "                    ind = 1\n",
    "    d = {}\n",
    "    #next the information is labeled\n",
    "    #new dict will be  organised by these labels to ease merging later\n",
    "    for filename in os.listdir(loc):\n",
    "        if \"BradLab.csv\" in filename:\n",
    "            path = os.path.join(loc,filename)\n",
    "            bl = pp.loadgroup(path)\n",
    "            for key in bl:\n",
    "                if \"BL\" in bl[key]:\n",
    "                    continue\n",
    "                elif dic[key] == \"\":\n",
    "                    continue\n",
    "                else:\n",
    "                    d[bl[key]] = dic[key]\n",
    "            #all entries containing \"0\" therefore being unused are deleted\n",
    "            if \"0\" in d.keys():\n",
    "                d.pop(\"0\")\n",
    "    for key in d:\n",
    "        d[key] = float(d[key])\n",
    "    return d\n",
    "\n",
    "def joinflourometry(dic, bf, header):\n",
    "    #joins the two loaded dicts (spark and Bradford)\n",
    "    import pandas as pd\n",
    "    d = dic\n",
    "    d[\"Bradford\"]={}\n",
    "    #loops through all wells in the spark file and collects the corresponding value from the bradford dict\n",
    "    #info is stored in the bradford entry in the spark dict\n",
    "    for wk in dic[\"Well\"]:\n",
    "        d[\"Bradford\"][wk] = bf[dic[\"Well\"][wk]]\n",
    "    df = pd.DataFrame.from_dict(d)\n",
    "    #realtive intensity is calculated\n",
    "    for h in header:\n",
    "        df[h+\"_rel\"] = df[h+\"_sub\"]/df[\"Bradford\"]\n",
    "    return df\n",
    "\n",
    "def normalize(d, header):\n",
    "    import pandas as pd\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    #normalisation is used to compare results from different measuremets\n",
    "    #all values are divided by mean of control variable\n",
    "    # usually this means \"X\" ond/or \"DMSO\"\n",
    "    if \"Group2\" in d:\n",
    "        dfs1 = []\n",
    "        for g1 in d[\"Group2\"].unique():\n",
    "\n",
    "            df1 = d[d[\"Group2\"]==g1]\n",
    "            for h in header:\n",
    "                median = df1[h+\"_rel\"][df1[\"Group1\"]==\"X\"].mean()\n",
    "                df1[h+\"_norm_X\"] = df1[h+\"_rel\"]/median\n",
    "            dfs1.append(df1)\n",
    "        d = pd.concat(dfs1)\n",
    "        dfs2 = []\n",
    "        for g2 in d[\"Group1\"].unique():\n",
    "            print(g1)\n",
    "            df1 = d[d[\"Group1\"]==g2]\n",
    "            for h in header:\n",
    "                median = df1[h+\"_rel\"][df1[\"Group2\"]==\"DMSO\"].mean()\n",
    "                print(median)\n",
    "                df1[h+\"_norm_DMSO\"] = df1[h+\"_rel\"]/median\n",
    "            dfs2.append(df1)\n",
    "        d = pd.concat(dfs2)\n",
    "    else:\n",
    "        for h in header:\n",
    "            median = d[h+\"_rel\"][d[\"Group1\"]==\"X\"].mean()\n",
    "            d[h+\"_norm\"] = d[h+\"_rel\"]/median\n",
    "    \n",
    "    return(d)\n",
    "\n",
    "def addtry(d, loc):\n",
    "    #this function adds a \"try\" variable to each entry\n",
    "    #value is defined by foldercontainig the information(either 1, 2,....)\n",
    "    #Folders need to be labeled i numbers in an ascending manner\n",
    "    import os\n",
    "    t = os.path.split(loc)\n",
    "    d[\"Try\"] = t[1]\n",
    "    return d\n",
    "\n",
    "def create_df_flourometry(loc):\n",
    "    #main function for creating a df for flourometry for a single try\n",
    "    import pathophys as pp\n",
    "    import pandas as pd\n",
    "    #loads spark file\n",
    "    dic, header = pp.loadspark(loc)\n",
    "    #loads bradfors information\n",
    "    bf = pp.loadbff(loc)\n",
    "    #joins them\n",
    "    d = pp.joinflourometry(dic, bf, header)\n",
    "    #Includes Bradford in normalisation\n",
    "    header.append(\"Bradford\")\n",
    "    d[\"Bradford_rel\"] = d[\"Bradford\"]\n",
    "    #Normalizes entries\n",
    "    nd = []\n",
    "\n",
    "    dd = pp.normalize(d, header)\n",
    "    nd.append(dd)\n",
    "    d = pd.concat(nd)\n",
    "    #Adds try\n",
    "    d = pp.addtry(d, loc)\n",
    "    return d\n",
    "\n",
    "def getdir(directory):\n",
    "    #searches for directories in main directory\n",
    "    #Dirs containing results have to be named after a single number up to 10\n",
    "    import os\n",
    "    locs = []\n",
    "    for i in range(1, 10):\n",
    "        loc = os.path.join(directory, str(i))\n",
    "        if os.path.isdir(loc):\n",
    "            print(loc)\n",
    "            locs.append(loc)\n",
    "    return locs\n",
    "\n",
    "def get_df_flourometry(specdir, boo):\n",
    "    #main function for returning a single df for all tries of the flourometry experiment\n",
    "    import pathophys as pp\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    parentdir = pp.getparentdir(specdir)\n",
    "    directory = os.path.join(parentdir, \"Flourometry\")\n",
    "    #locs is a list of all tries\n",
    "    locs = pp.getdir(directory)\n",
    "    dfs = []\n",
    "    for loc in locs:\n",
    "        #df from a single try gets created and appended to a list of dataframes\n",
    "        df = pp.create_df_flourometry(loc)\n",
    "        dfs.append(df)\n",
    "    #dataframes are combined and their indexes reset\n",
    "    df = pd.concat(dfs)\n",
    "    df = df.reset_index(drop=True)\n",
    "    #results are saved as csv\n",
    "    resultsloc1 = os.path.join(parentdir, \"Flourometry\")\n",
    "    resultsloc = os.path.join(resultsloc1, \"Results.csv\")\n",
    "    df.to_csv(resultsloc)\n",
    "    if boo != True:\n",
    "        df = df[df[\"Try\"]==boo]\n",
    "    #print(df.to_string())\n",
    "    display(df)\n",
    "    return df\n",
    "    \n",
    "\n",
    "def load_dens(loc):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    densloc = os.path.join(loc, \"Densitometry\")\n",
    "    files = os.listdir(densloc)\n",
    "    targets = []\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        path = os.path.join(densloc, file)\n",
    "        target = file.split(\"_\")[0]\n",
    "        targets.append(target)\n",
    "        df = pd.read_csv(path)\n",
    "        d = pd.DataFrame()\n",
    "        d[\"Lane\"] = df[\" \"]\n",
    "        d[target] = df[\"Area\"]\n",
    "        dfs.append(d)\n",
    "        \n",
    "    d = dfs[0]\n",
    "    #print(d)\n",
    "    dcs = []\n",
    "    for i in range(1, len(dfs)):\n",
    "        d = d.join(dfs[i], rsuffix = str(i))\n",
    "        dc = \"Lane\"+str(i)\n",
    "        dcs.append(dc)\n",
    "    df = d.drop(columns=dcs)\n",
    "    return df, targets\n",
    "\n",
    "def translatewb(l):\n",
    "    import string\n",
    "    import pandas as pd\n",
    "    data = {\"Lane\": [], \"Group1\": [], \"Group2\": [] ,\"Group3\": []}\n",
    "    for key in l:\n",
    "        ABC = list(string.ascii_uppercase)\n",
    "        ind = ABC.index(key[0])+1\n",
    "        if ind not in data[\"Lane\"]:\n",
    "            data[\"Lane\"].append(ind)\n",
    "        data[\"Group\"+key[1]].append(l[key])\n",
    "    d = {}\n",
    "    for key in data:\n",
    "        if len(data[key]) != 0:\n",
    "            d[key] = data[key]\n",
    "    df = pd.DataFrame(data = d)\n",
    "    return df\n",
    "\n",
    "def create_df_wb(loc):\n",
    "    import pathophys as pp\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    df, targets = pp.load_dens(loc)\n",
    "    l = pp.loadgroup(os.path.join(loc, \"Lanes.csv\"))\n",
    "    l = pp.translatewb(l)\n",
    "    d = pd.merge(df, l)\n",
    "    if \"b-Actin\" in d:\n",
    "        for t in targets:\n",
    "            d[t+\"_rel\"] = d[t]/d[\"b-Actin\"]\n",
    "        d[\"b-Actin_rel\"] = d[\"b-Actin\"]\n",
    "    elif \"Ponceau\" in d:\n",
    "        for t in targets:\n",
    "            d[t+\"_rel\"] = d[t]/d[\"Ponceau\"]\n",
    "        d[\"Ponceau_rel\"] = d[\"Ponceau\"]\n",
    "    d = pp.normalize(d, targets)\n",
    "    d = pp.addtry(d, loc)\n",
    "    return d\n",
    "\n",
    "def get_df_wb(specdir, boo):\n",
    "    import pathophys as pp\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    parentdir = pp.getparentdir(specdir)\n",
    "    directory = os.path.join(parentdir, \"WB\")\n",
    "    locs = pp.getdir(directory)\n",
    "    dfs = []\n",
    "    for loc in locs:\n",
    "        df = pp.create_df_wb(loc)\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs)\n",
    "    df = df.reset_index(drop=True)\n",
    "    resultsloc1 = os.path.join(parentdir, \"WB\")\n",
    "    resultsloc = os.path.join(resultsloc1, \"Results.csv\")\n",
    "    df.to_csv(resultsloc)\n",
    "    if boo != True:\n",
    "        df = df[df[\"Try\"]==boo]\n",
    "    display(df)\n",
    "    return df\n",
    "\n",
    "def convert_pvalue_to_asterisks(pvalue):\n",
    "    if pvalue <= 0.0001:\n",
    "        return \"****\"\n",
    "    elif pvalue <= 0.001:\n",
    "        return \"***\"\n",
    "    elif pvalue <= 0.01:\n",
    "        return \"**\"\n",
    "    elif pvalue <= 0.05:\n",
    "        return \"*\"\n",
    "    return \"ns\"\n",
    "\n",
    "def calculatepvalues(df, x, y, ctrl, treatment):\n",
    "    import pathophys as pp\n",
    "    from scipy.stats import kstest, mannwhitneyu, ttest_ind\n",
    "    kres = kstest(df[y], 'norm')\n",
    "    pv = 0\n",
    "    if kres[1] > 0.05:\n",
    "        pv = ttest_ind(df[y][df[x] == ctrl], df[y][df[x] == treatment], alternative=\"two-sided\")\n",
    "        print(\"T-Test\")\n",
    "    else:\n",
    "        pv = mannwhitneyu(df[y][df[x] == ctrl], df[y][df[x] == treatment], alternative=\"two-sided\")\n",
    "        print(\"MWY\")\n",
    "    p = pv[1]\n",
    "    print(ctrl+\" vs. \"+treatment+\": \"+str(p))\n",
    "    pa = pp.convert_pvalue_to_asterisks(p)\n",
    "    return pa\n",
    "    \n",
    "def drawsigbars(df, ax, x, y, ctrl, treatment, maxv, y_range, diff):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pathophys as pp\n",
    "    maxv = maxv+(y_range*0.15)\n",
    "    ax.plot(\n",
    "        [ctrl, ctrl, treatment, treatment],\n",
    "        [maxv, maxv, maxv, maxv], lw=1, c='k'\n",
    "    )\n",
    "    p = pp.calculatepvalues(df, x, y, ctrl, treatment)    \n",
    "    ax.text((diff), maxv, p, ha='center', va='bottom', fontsize=11)\n",
    "    \n",
    "    \n",
    "def barplot3(ax, df, x, y, z, bw, ls, sigp):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    import math as mat\n",
    "    import matplotlib as mpl\n",
    "    import pathophys as pp\n",
    "    import pandas as pd\n",
    "\n",
    "    maxvs = []\n",
    "    cond = []\n",
    "    #plt.scatter(df[\"Group1\"],df[\"Mean_norm\"])\n",
    "    ns = len(df[\"Try\"].unique())\n",
    "    print(\"n = \"+str(ns))\n",
    "\n",
    "    for g in df[x].unique():\n",
    "        \n",
    "        cond.append(g)\n",
    "        data = pd.to_numeric(df[y][df[x]==g])\n",
    "        sd = data.std()\n",
    "        if mat.isnan(sd) == True:\n",
    "            sd = 0\n",
    "        ci = 1.96*sd/mat.sqrt(len(data))\n",
    "        label = g\n",
    "        if g == \"X\":\n",
    "            label = \"Ctrl\"\n",
    "        ax.bar(g, data.mean(), bw, yerr=ci, capsize=4, linewidth=ls, edgecolor=\"black\")\n",
    "        maxvs.append(data.mean()+ci)\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(ls)\n",
    "        if axis in ['top','right']:\n",
    "            ax.spines[axis].set_visible(False)\n",
    "    ax.tick_params(width=ls)\n",
    "    maxv = max(maxvs)\n",
    "    hightind = 0\n",
    "    bottom, top = ax.get_ylim()\n",
    "    y_range = top - bottom\n",
    "    treatmenti = 0\n",
    "    for pairs in sigp:\n",
    "        c1 = pairs[0]\n",
    "        ctrli = cond.index(c1)\n",
    "        c2 = pairs[1]\n",
    "        treatmenti = cond.index(c2)\n",
    "\n",
    "        diff = (treatmenti-ctrli)/2\n",
    "        pp.drawsigbars(df, ax, x, y, c1, c2, maxv+hightind, y_range, diff)\n",
    "        hightind = hightind + y_range*0.2\n",
    "    return(ax)\n",
    "\n",
    "def barplot3wb(ax, df, x, y, z, bw, ls, sigp):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    import math as mat\n",
    "    import matplotlib as mpl\n",
    "    import pathophys as pp\n",
    "    import pandas as pd\n",
    "\n",
    "    maxvs = []\n",
    "    cond = []\n",
    "    #plt.scatter(df[\"Group1\"],df[\"Mean_norm\"])\n",
    "    ns = len(df[\"Try\"].unique())\n",
    "    print(\"n = \"+str(ns))\n",
    "\n",
    "    for g in df[x].unique():\n",
    "        \n",
    "        cond.append(g)\n",
    "        data = pd.to_numeric(df[y][df[x]==g])\n",
    "        sd = data.std()\n",
    "        if mat.isnan(sd) == True:\n",
    "            sd = 0\n",
    "        ci = 1.96*sd/mat.sqrt(len(data))\n",
    "        label = g\n",
    "        if g == \"X\":\n",
    "            label = \"Ctrl\"\n",
    "        ax.bar(g, data.mean(), bw, yerr=ci, capsize=4, linewidth=ls, edgecolor=\"black\")\n",
    "        maxvs.append(data.mean()+ci)\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(ls)\n",
    "        if axis in ['top','right']:\n",
    "            ax.spines[axis].set_visible(False)\n",
    "    ax.tick_params(width=ls)\n",
    "    return(ax)\n",
    "\n",
    "def settitle(ax, alpha, title):\n",
    "    ax.set_title(title, fontsize=11)\n",
    "    ax.set_title(alpha, loc=\"left\", fontsize=20, fontweight=\"bold\", pad=15)\n",
    "    \n",
    "def loadparams():\n",
    "    import csv\n",
    "    d = {}\n",
    "    loc = \"E:\\Raphael\\Data\\FigureParams.csv\"\n",
    "    with open(loc) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=\";\")\n",
    "        psd = {}\n",
    "        colors = []\n",
    "        switch = \"\"\n",
    "        for row in reader:\n",
    "            if row[0] == \"End\":\n",
    "                switch=\"\"\n",
    "            elif switch == \"PS\":\n",
    "                psd[row[0]] = row[1]\n",
    "            elif switch == \"Params\":\n",
    "                d[row[0]]=row[1]\n",
    "            elif switch == \"Colors\":\n",
    "                c = row[1]\n",
    "                if c != \"\":\n",
    "                    colors.append(c)\n",
    "            elif \"ProteinSize\" in row[0]:\n",
    "                switch = \"PS\"\n",
    "            elif \"PlotParams\" in row[0]:\n",
    "                switch = \"Params\"\n",
    "            elif \"Colors\" in row[0]:\n",
    "                switch = \"Colors\"\n",
    "        d[\"Colors\"] = colors\n",
    "        d[\"ProteinSize\"] = psd\n",
    "    return d\n",
    "\n",
    "def loadplan(directory):\n",
    "    import os\n",
    "    import csv\n",
    "    import numpy\n",
    "    file = os.path.join(directory, \"FigurePlan.csv\")\n",
    "    d = {}\n",
    "    with open(file) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=\";\")\n",
    "        switch = \"\"\n",
    "        figdic = {}\n",
    "        for row in reader:\n",
    "            rarr = []\n",
    "            if row[0] == \"End\":\n",
    "                switch=\"\"\n",
    "            elif switch == \"Layout\":\n",
    "                cc = 0\n",
    "                rn = 0\n",
    "                for collumn in row:\n",
    "                    if cc == 0:\n",
    "                        rn = int(collumn)\n",
    "                    else:\n",
    "                        cn = cc-1\n",
    "                        if collumn not in figdic:\n",
    "                            figdic[collumn] = []\n",
    "                        figdic[collumn].append([cn, rn])\n",
    "                    cc = cc+1\n",
    "            elif switch == \"F\":\n",
    "                cc = 0\n",
    "                lab = \"\"\n",
    "                for collumn in row:\n",
    "                    if cc == 0:\n",
    "                        lab = collumn\n",
    "                    elif collumn != \"\":\n",
    "                        fig = switch+\"_\"+str(cc-1)\n",
    "                        if fig not in d:\n",
    "                            d[fig] = {}\n",
    "                        d[fig][lab] = collumn\n",
    "                    cc = cc+1\n",
    "            elif switch == \"WB\":\n",
    "                cc = 0\n",
    "                lab = \"\"\n",
    "                for collumn in row:\n",
    "                    if cc == 0:\n",
    "                        lab = collumn\n",
    "                    elif collumn != \"\":\n",
    "                        fig = switch+\"_\"+str(cc-1)\n",
    "                        if fig not in d:\n",
    "                            d[fig] = {}\n",
    "                        d[fig][lab] = collumn\n",
    "                    cc = cc+1\n",
    "            elif switch == \"D\":\n",
    "                cc = 0\n",
    "                lab = \"\"\n",
    "                for collumn in row:\n",
    "                    if cc == 0:\n",
    "                        lab = collumn\n",
    "                    elif collumn != \"\":\n",
    "                        fig = switch+\"_\"+str(cc-1)\n",
    "                        if fig not in d:\n",
    "                            d[fig] = {}\n",
    "                        d[fig][lab] = collumn\n",
    "                    cc = cc+1\n",
    "            elif switch == \"BL\":\n",
    "                cc = 0\n",
    "            elif \"Grid\" in row[0]:\n",
    "                switch=\"Layout\"\n",
    "            elif \"F\" in row[0]:\n",
    "                switch=\"F\"\n",
    "            elif \"WB\" in row[0]:\n",
    "                switch=\"WB\"\n",
    "            elif \"D\" in row[0]:\n",
    "                switch=\"D\"\n",
    "            elif \"BL\" in row[0]:\n",
    "                switch=\"BL\"\n",
    "        figdic.pop(\"\")\n",
    "        for key in figdic:\n",
    "            d[key][\"Grid\"] = figdic[key]\n",
    "    return(d)         \n",
    "            \n",
    "def getdim(p):\n",
    "    \n",
    "    arr = [[],[]]\n",
    "    ratiodict= {\"F\":1,\"WB\":2,\"D\":1,\"WBXL\":3, \"DXL\":3, \"FXL\":3}\n",
    "    ratios = {}\n",
    "    \n",
    "    pop = []\n",
    "    for key in p:\n",
    "        if \"Grid\" not in  p[key]:\n",
    "            pop.append(key)\n",
    "    for po in pop:\n",
    "        p.pop(po)\n",
    "    for key in p:\n",
    "        for a in p[key][\"Grid\"]:\n",
    "            for i in range(len(a)):\n",
    "                p[key][\"loc\"+str(i)] = a[i]\n",
    "                arr[i].append(a[i])\n",
    "            if a[1] not in ratios:\n",
    "                ratios[a[1]] = []\n",
    "            ratios[a[1]].append(key)\n",
    "    print(ratios)\n",
    "    for key in p:\n",
    "        r = \"\"\n",
    "        if \"XL\" in p[key]:\n",
    "            if p[key][\"XL\"] == \"TRUE\":\n",
    "                r = key.split(\"_\")[0]+\"XL\"\n",
    "            else:\n",
    "                r = key.split(\"_\")[0]\n",
    "        else:\n",
    "            r = key.split(\"_\")[0]\n",
    "        #for a in p[key][\"Grid\"]:\n",
    "            #ratios[a[1]][int(a[0])] = ratiodict[r]         \n",
    "    dim = []\n",
    "    for ar in arr:\n",
    "        dim.append(max(ar)+1)\n",
    "    ratio = []\n",
    "    for key in ratios:\n",
    "        rt = [0]*len(ratios[key])\n",
    "        for plot in ratios[key]:\n",
    "            indratio = ratiodict[plot.split(\"_\")[0]]\n",
    "            rank = p[plot][\"Grid\"][0][0]\n",
    "            print(rank)\n",
    "            rt[int(rank)] = indratio\n",
    "        ratio.append(rt)\n",
    "    return dim, p, ratio\n",
    "\n",
    "def reorganise(d):\n",
    "    dn = {}\n",
    "    for key in d:\n",
    "        l0 = d[key][\"loc0\"]\n",
    "        l1 = d[key][\"loc1\"]\n",
    "        if l1 not in dn:\n",
    "            dn[l1] = {l0:d[key]}\n",
    "        else:\n",
    "            dn[l1][l0] = d[key]\n",
    "        dn[l1][l0][\"Ex\"] = key\n",
    "    return dn\n",
    "\n",
    "def setlabel(ax, xl, yl):\n",
    "    ax.set_xlabel(xl, fontsize=11)\n",
    "    ax.set_ylabel(yl, fontsize=11)\n",
    "            \n",
    "def getFimage(sf, p, params, fc, directory):\n",
    "    import pathophys as pp\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import string\n",
    "    import pathophys as pp\n",
    "    print(\"Flourometry\")\n",
    "    alphabet = list(string.ascii_lowercase)\n",
    "    fn = \"Flourometry\"+p[\"Ex\"].split(\"_\")[1]\n",
    "    if fn not in os.listdir(directory):\n",
    "        fn = \"Flourometry\"\n",
    "    dfd = os.path.join(directory, fn)\n",
    "    file = os.path.join(dfd, \"Results.csv\")\n",
    "    df = pd.read_csv(file)\n",
    "    df[\"Mean_rel\"] = df[\"Mean_rel\"]/1000\n",
    "    bw = float(params[\"BarSize\"])\n",
    "    ls = float(params[\"LS\"])\n",
    "    x = p[\"X\"]\n",
    "    y = p[\"Y\"]\n",
    "    z = p[\"Z\"]\n",
    "    sigp =[]\n",
    "    for key in p:\n",
    "        if \"Sig\"in key:\n",
    "            sigp.append(p[key].split(\"_\"))\n",
    "    ax = pp.barplot3(sf.subplots(1, 1, sharey=True), df, x, y, z, bw, ls, sigp)\n",
    "    title = p[\"Title\"]\n",
    "    alpha = alphabet[fc]\n",
    "    pp.settitle(ax, alpha, title)\n",
    "    xl = p[\"Label_X\"]\n",
    "    yl = p[\"Label_Y\"]\n",
    "    pp.setlabel(ax, xl, yl)\n",
    "    \n",
    "def getDimage(sf, p, params, fc, directory):\n",
    "    import pathophys as pp\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import string\n",
    "    import pathophys as pp\n",
    "    print(\"Densitometry\")\n",
    "    alphabet = list(string.ascii_lowercase)\n",
    "    fn = \"WB\"+p[\"Ex\"].split(\"_\")[1]\n",
    "    if fn not in os.listdir(directory):\n",
    "        fn = \"WB\"\n",
    "    dfd = os.path.join(directory, fn)\n",
    "    file = os.path.join(dfd, \"Results.csv\")\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    bw = float(params[\"BarSize\"])\n",
    "    ls = float(params[\"LS\"])\n",
    "    x = p[\"X\"]\n",
    "    y = p[\"Y\"]\n",
    "    z = p[\"Z\"]\n",
    "    sigp =[]\n",
    "    for key in p:\n",
    "        if \"Sig\"in key:\n",
    "            sigp.append(p[key].split(\"_\"))\n",
    "    ax = pp.barplot3wb(sf.subplots(1, 1, sharey=True), df, x, y, z, bw, ls, sigp)\n",
    "    title = p[\"Title\"]\n",
    "    alpha = alphabet[fc]\n",
    "    pp.settitle(ax, alpha, title)\n",
    "    xl = p[\"Label_X\"]\n",
    "    yl = p[\"Label_Y\"]\n",
    "    pp.setlabel(ax, xl, yl)\n",
    "\n",
    "def plotWB(ax, path, protein, size):\n",
    "    #import numpy as np\n",
    "    import matplotlib.image as mpimg\n",
    "    import matplotlib.pyplot as plt\n",
    "    img = mpimg.imread(path)\n",
    "    ax = ax.imshow(img, aspect='auto')\n",
    "    return ax\n",
    "\n",
    "def makegroups(d):\n",
    "    c = {}\n",
    "    for key in d:\n",
    "        if \"C_\" in key:\n",
    "            c[key.split(\"_\")[1]] = d[key]\n",
    "    cc = len(c)\n",
    "    g = []\n",
    "    for i in range(2*cc+1):\n",
    "        if ((i+1) % 2) == 0:\n",
    "            g.append(c[str(int((i+1)/2))])\n",
    "        else:\n",
    "            g.append(\" \")\n",
    "    if d[\"Dls\"] == \"TRUE\":\n",
    "        g.append(\" \")\n",
    "    g = [g]\n",
    "    return g\n",
    "    \n",
    "\n",
    "def getWBimg(sf, p, params, fc, directory):\n",
    "    import os\n",
    "    import pathophys as pp\n",
    "    import matplotlib.pyplot as plt\n",
    "    import string\n",
    "    alphabet = list(string.ascii_lowercase)\n",
    "    extra = int(p[\"#extra\"])\n",
    "    folder = os.path.join(directory, \"WB\")\n",
    "    folder = os.path.join(folder, \"Img_Final\")\n",
    "    protein_size_db = params[\"ProteinSize\"]\n",
    "    imgs = os.listdir(folder)\n",
    "    hr = [2]\n",
    "    for i in range(len(imgs)+extra):\n",
    "        hr.append(1)\n",
    "    wbax = sf.subfigures(len(imgs)+extra+1, height_ratios=hr)\n",
    "    ic = 0\n",
    "    groups = pp.makegroups(p)\n",
    "    title = p[\"Title\"]\n",
    "    alpha = alphabet[fc]\n",
    "    ls = params[\"LS\"]\n",
    "    for bax in wbax:\n",
    "        ax = bax.subplots(1, 1)\n",
    "        if ic == 0:\n",
    "            tab = ax.table(cellText=groups, cellLoc=\"center\", edges=\"open\", rowLabels=[\"kD\"])\n",
    "            tab.set_fontsize(14)\n",
    "            ax.axis('tight')\n",
    "            ax.axis('off')\n",
    "            pp.settitle(ax, alpha, title)\n",
    "            ic = ic+1\n",
    "        elif ic <= len(imgs):\n",
    "            img = imgs[ic-1]\n",
    "            path2img = os.path.join(folder, img)\n",
    "            imginfo = img.split(\"_\")\n",
    "            rank = int(imginfo[0])\n",
    "            protein = imginfo[1].split(\".\")[0]\n",
    "            print(protein)\n",
    "            print(protein_size_db)\n",
    "            size = protein_size_db[protein]\n",
    "            print(size)\n",
    "            pc = plotWB(ax, path2img, protein, size)\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                ax.spines[axis].set_linewidth(ls)\n",
    "            ax.tick_params(bottom=False, left=False)\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_xticklabels([])\n",
    "            t1 = ax.table(cellText=[[size]], cellLoc=\"center\", edges=\"open\",loc=\"left\", colWidths=[0.1])\n",
    "            t1.set_fontsize(14)\n",
    "            t2 = ax.table(cellText=[[protein]], cellLoc=\"center\", edges=\"open\", loc=\"right\", colWidths=[0.2])\n",
    "            t2.set_fontsize(14)\n",
    "            ic = ic+1\n",
    "        else:\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                ax.spines[axis].set_visible(False)\n",
    "            ax.tick_params(bottom=False, left=False)\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_xticklabels([])\n",
    "\n",
    "def makeBlank(sf, p):\n",
    "    ax = sf.plot()\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_visible(False)\n",
    "            \n",
    "def createsubplot(sf, plan, fc, switch, params, directory):\n",
    "    import pathophys as pp\n",
    "\n",
    "    p = plan\n",
    "    gt = plan[\"Ex\"].split(\"_\")[0]\n",
    "    if gt==\"F\":\n",
    "        pp.getFimage(sf, p, params, fc, directory)\n",
    "        fc = fc+1\n",
    "    elif gt==\"WB\":\n",
    "        pp.getWBimg(sf, p, params, fc, directory)\n",
    "        fc = fc+1\n",
    "    elif gt==\"D\":\n",
    "        pp.getDimage(sf, p, params, fc, directory)\n",
    "        fc = fc+1\n",
    "    elif gt==\"BL\":\n",
    "        pp.makeBlank(sf, p)\n",
    "    else:\n",
    "        return\n",
    "    return fc\n",
    " \n",
    "    \n",
    "def createfigure(specdir, fs):\n",
    "    #creates figure automatically\n",
    "    #requires: folder named \"Figure x\" with x being a number,...\n",
    "    #a csv named \"Figure_Plan\" containing all information about the figure,...\n",
    "    #a csv-file named \"Figure_Params\" containing the settings for all figures like color and line sizes\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pathophys as pp\n",
    "    import os\n",
    "    cm = 1/2.54\n",
    "    fdirectory = \"\"\n",
    "    #look for directory containing experiment\n",
    "    parentdir = pp.getparentdir(specdir)\n",
    "    #lokk inside for the \"Figure x\" folder\n",
    "    for d in os.listdir(parentdir):\n",
    "        if \"Figure\" in d:\n",
    "            fdirectory = os.path.join(parentdir, d)\n",
    "    #load parameters from \"Figure_Params\" file (always stored in same location)\n",
    "    params = pp.loadparams()\n",
    "\n",
    "    #load specific settings from \"Figure_Plan\" file\n",
    "    plan = pp.loadplan(fdirectory)\n",
    "\n",
    "    #extracts information about dimension form \"plan\"\n",
    "    dim, plan, ratios = pp.getdim(plan)\n",
    "    sns.set_palette(sns.color_palette(params[\"Colors\"]))\n",
    "    #initializes figure\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(fs[0], fs[1]))\n",
    "\n",
    "    subfigs1 = fig.subfigures(dim[1])\n",
    "    fc = 0\n",
    "    plan = pp.reorganise(plan)\n",
    "    for i in range(dim[1]):\n",
    "        subfigs2 = None\n",
    "        if dim[1] == 1:\n",
    "            subfigs2 = subfigs1.subfigures(1, len(ratios[i]), wspace=float(params[\"wspace\"]), width_ratios=ratios[i])\n",
    "        else:\n",
    "            print(ratios, dim, i, params)\n",
    "            subfigs2 = subfigs1[i].subfigures(1, len(ratios[i]), wspace=float(params[\"wspace\"]), width_ratios=ratios[i])\n",
    "\n",
    "        for key in plan[i]:\n",
    "            sp = plan[i][key]\n",
    "\n",
    "            if len(ratios[i]) == 1:\n",
    "                fc = pp.createsubplot(subfigs2,sp, fc, 0, params, parentdir)\n",
    "            else:\n",
    "                fc = pp.createsubplot(subfigs2[key],sp, fc, 0, params, parentdir)\n",
    "    pathimg = os.path.join(fdirectory, \"Figure_\"+specdir+\".png\")\n",
    "    fig.savefig(pathimg)\n",
    "    \n",
    "def plottriesf(df, x, y, z):\n",
    "    import pathophys as pp\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    add = 1\n",
    "    if z in df:\n",
    "        add = 0\n",
    "        add = add+len(df[\"Group2\"].unique())\n",
    "    fs = [2*add,len(df[\"Try\"].unique())*3]\n",
    "    params = pp.loadparams()\n",
    "    sns.set_palette(sns.color_palette(params[\"Colors\"]))\n",
    "    print(df[\"Try\"].unique())\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(fs[0], fs[1]))\n",
    "    subfigs = fig.subfigures(len(df[\"Try\"].unique())+1, wspace=0.1)\n",
    "    tc = 0\n",
    "    bw = 0.8\n",
    "    ls = 2\n",
    "    sigp = []\n",
    "    if z == \"None\":\n",
    "        for t in df[\"Try\"].unique():\n",
    "            ndf = df[df[\"Try\"]==t]\n",
    "            pl = pp.barplot3(subfigs[tc].subplots(1, 1, sharey=True), ndf, x, y, z, bw, ls, sigp)\n",
    "            pl.set_title(\"T\"+t, loc=\"left\", fontsize=\"xx-large\", fontweight=\"bold\", pad=15)\n",
    "            tc = tc+1\n",
    "        pl = pp.barplot3(subfigs[tc].subplots(1, 1, sharey=True), df, x, y, z, bw, ls, sigp)\n",
    "    else:\n",
    "        for t in df[\"Try\"].unique():\n",
    "            ndf = df[df[\"Try\"]==t]\n",
    "            sf2 = subfigs[tc].subfigures(1,len(df[z].unique()), wspace=0.1)\n",
    "            subfigs[tc].suptitle(\"T\"+t, horizontalalignment=\"left\", fontsize=\"xx-large\", fontweight=\"bold\")\n",
    "            tc2 = 0\n",
    "            for gf2 in ndf[z].unique():\n",
    "                ndf2 = ndf[ndf[z]==gf2]\n",
    "                pl = pp.barplot3(sf2[tc2].subplots(1, 1, sharey=True), ndf2, x, y, z, bw, ls, sigp)\n",
    "                pl.set_title(gf2, loc=\"left\", fontsize=\"large\", fontweight=\"bold\", pad=15)\n",
    "                tc2 = tc2+1\n",
    "            tc = tc+1\n",
    "        sf1 = subfigs[tc].subfigures(1,len(df[z].unique()), wspace=0.1)\n",
    "        subfigs[tc].suptitle(\"Combined\", horizontalalignment=\"left\", fontsize=\"xx-large\", fontweight=\"bold\")\n",
    "        tc2 = 0\n",
    "        for gf in df[z].unique():\n",
    "            ndf1 = df[df[z]==gf]\n",
    "            pl = pp.barplot3(sf1[tc2].subplots(1, 1, sharey=True), ndf1, x, y, z, bw, ls, sigp)\n",
    "            pl.set_title(gf, loc=\"left\", fontsize=\"large\", fontweight=\"bold\", pad=15)\n",
    "            tc2 = tc2+1\n",
    "    \n",
    "def plottrieswb(df, x, y, z):\n",
    "    import pathophys as pp\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    add = 1\n",
    "    if \"Group2\" in df:\n",
    "        add = 0\n",
    "        add = add+len(df[\"Group2\"].unique())\n",
    "    fs = [2*add,len(df[\"Try\"].unique())*3]\n",
    "    params = pp.loadparams()\n",
    "    sns.set_palette(sns.color_palette(params[\"Colors\"]))\n",
    "    print(df[\"Try\"].unique())\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(fs[0], fs[1]))\n",
    "    subfigs = fig.subfigures(len(df[\"Try\"].unique())+1, wspace=0.1)\n",
    "    tc = 0\n",
    "    bw = 0.8\n",
    "    ls = 2\n",
    "    sigp = []\n",
    "    if z == \"None\":\n",
    "        for t in df[\"Try\"].unique():\n",
    "            ndf = df[df[\"Try\"]==t]\n",
    "            pl = pp.barplot3(subfigs[tc].subplots(1, 1, sharey=True), ndf, x, y, z, bw, ls, sigp)\n",
    "            pl.set_title(\"T\"+t, loc=\"left\", fontsize=\"xx-large\", fontweight=\"bold\", pad=15)\n",
    "            tc = tc+1\n",
    "        pl = pp.barplot3(subfigs[tc].subplots(1, 1, sharey=True), df, x, y, z, bw, ls, sigp)\n",
    "    else:\n",
    "        for t in df[\"Try\"].unique():\n",
    "            ndf = df[df[\"Try\"]==t]\n",
    "            sf2 = subfigs[tc].subfigures(1,len(ndf[z].unique()), wspace=0.1)\n",
    "            subfigs[tc].suptitle(\"T\"+t, horizontalalignment=\"left\", fontsize=\"xx-large\", fontweight=\"bold\")\n",
    "            tc2 = 0\n",
    "            for gf2 in ndf[z].unique():\n",
    "                ndf2 = ndf[ndf[z]==gf2]\n",
    "                pl = pp.barplot3(sf2[tc2].subplots(1, 1, sharey=True), ndf2, x, y, z, bw, ls, sigp)\n",
    "                pl.set_title(gf2, loc=\"left\", fontsize=\"large\", fontweight=\"bold\", pad=15)\n",
    "                tc2 = tc2+1\n",
    "            tc = tc+1\n",
    "        sf1 = subfigs[tc].subfigures(1,len(df[z].unique()), wspace=0.1)\n",
    "        subfigs[tc].suptitle(\"Combined\", horizontalalignment=\"left\", fontsize=\"xx-large\", fontweight=\"bold\")\n",
    "        tc2 = 0\n",
    "        for gf in df[z].unique():\n",
    "            ndf1 = df[df[z]==gf]\n",
    "            pl = pp.barplot3(sf1[tc2].subplots(1, 1, sharey=True), ndf1, x, y, z, bw, ls, sigp)\n",
    "            pl.set_title(gf, loc=\"left\", fontsize=\"large\", fontweight=\"bold\", pad=15)\n",
    "            tc2 = tc2+1\n",
    "\n",
    "def splitimages(experiment, rep):\n",
    "    import nd2\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import tifffile as tiff\n",
    "    basedir = \"\"\n",
    "    rawdir = \"\"\n",
    "    splitdir = \"\"\n",
    "    data = \"E:\\Raphael\\Data\"\n",
    "    for folder in os.listdir(data):\n",
    "        if str(experiment) in folder:\n",
    "            basedir = os.path.join(os.path.join(data, folder),str(rep))\n",
    "            rawdir = os.path.join(basedir,\"Raw images\")\n",
    "            splitdir = os.path.join(basedir,\"Images_Split\")\n",
    "    data = {\"ID\":[], \"PID\":[], \"Stack\":[], \"Channel\": [], \"xlen\": [], \"ylen\":[], \"zlen\": [], \"Group1\":[], \"Group2\":[]}\n",
    "    ID = 0\n",
    "    for ndimg in os.listdir(rawdir):\n",
    "        PID = 0\n",
    "        iml = os.path.join(rawdir, ndimg)\n",
    "        with nd2.ND2File(iml) as ndfile:\n",
    "            meta = ndfile.metadata\n",
    "            shape = ndfile.shape\n",
    "            for series in range(shape[0]):\n",
    "                stackID = 0\n",
    "                for stack in range(shape[1]):\n",
    "                    for i in range(len(meta.channels)):\n",
    "                        img = ndfile.asarray(PID)\n",
    "                        img = img[:,stackID,i,:,:]\n",
    "                        tiff.imwrite(os.path.join(splitdir,str(ID))+\".tif\", img)\n",
    "                        chan = meta.channels[i].channel.name\n",
    "                        xlen, ylen, zlen = meta.channels[i].volume.axesCalibration\n",
    "                        data[\"ID\"].append(str(ID))\n",
    "                        data[\"PID\"].append(str(PID))\n",
    "                        data[\"Stack\"].append(str(stackID))\n",
    "                        data[\"Channel\"].append(str(chan))\n",
    "                        data[\"xlen\"].append(xlen)\n",
    "                        data[\"ylen\"].append(ylen)\n",
    "                        data[\"zlen\"].append(zlen)\n",
    "                        data[\"Group1\"].append(ndimg.split(\"_\")[0])\n",
    "                        data[\"Group2\"].append(ndimg.split(\"_\")[1])\n",
    "                        ID = ID+1\n",
    "                    stackID = stackID+1\n",
    "                PID = PID+1\n",
    "    df = pd.DataFrame(data = data)\n",
    "    df.to_csv(os.path.join(basedir, \"Info.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e0e1627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Raphael\\Data\\5. Plasmid-mediated degradation does not get affected by Inhibition of Autophagy\\Flourometry\\1\n",
      "E:\\Raphael\\Data\\5. Plasmid-mediated degradation does not get affected by Inhibition of Autophagy\\Flourometry\\2\n",
      "E:\\Raphael\\Data\\5. Plasmid-mediated degradation does not get affected by Inhibition of Autophagy\\Flourometry\\3\n",
      "E:\\Raphael\\Data\\5. Plasmid-mediated degradation does not get affected by Inhibition of Autophagy\\Flourometry\\4\n",
      "CQ\n",
      "143499.62299577042\n",
      "32153.041073413257\n",
      "157362.37398347835\n",
      "141277.05771591538\n",
      "156811.9661016495\n",
      "148934.46118321244\n",
      "114502.13776448325\n",
      "0.114075\n",
      "CQ\n",
      "95736.09183844333\n",
      "24205.378837816814\n",
      "108311.20364872256\n",
      "95709.91038862184\n",
      "130981.62294795424\n",
      "80806.8592578358\n",
      "64276.36819005618\n",
      "0.112875\n",
      "CQ\n",
      "71514.34995719617\n",
      "13545.097824059623\n",
      "99140.66220178852\n",
      "69849.02672145695\n",
      "73390.67117656217\n",
      "64286.888274069766\n",
      "52238.4456267472\n",
      "0.11885000000000001\n",
      "BAF\n",
      "101729.07759800053\n",
      "35596.81614615984\n",
      "85114.59303005351\n",
      "133840.33645877265\n",
      "128092.07049827623\n",
      "64510.930600937405\n",
      "98550.58032861838\n",
      "0.10835\n",
      "BAF\n",
      "46756.458205995295\n",
      "13713.913153126146\n",
      "32227.439102651515\n",
      "50282.2290735651\n",
      "64325.35616035147\n",
      "46375.479247023366\n",
      "42027.95565358292\n",
      "0.10885\n",
      "BAF\n",
      "38781.977252886085\n",
      "7382.119553207499\n",
      "36007.51348244745\n",
      "51834.996331691626\n",
      "37827.88857222177\n",
      "46729.71445058721\n",
      "22997.327963406686\n",
      "0.10660000000000001\n",
      "BAF\n",
      "124361.77182949238\n",
      "18720.83884195527\n",
      "130762.53006790002\n",
      "121558.65889151218\n",
      "147860.9814552696\n",
      "117210.20580339135\n",
      "103612.18066164824\n",
      "0.130575\n",
      "BAF\n",
      "62744.29807621498\n",
      "6146.522137711994\n",
      "62731.463802101236\n",
      "76428.27382479756\n",
      "61243.40544310178\n",
      "58890.68759796572\n",
      "53623.84027873739\n",
      "0.130825\n",
      "BAF\n",
      "83170.98888340409\n",
      "14732.093345920499\n",
      "93996.51890060518\n",
      "92627.08850228412\n",
      "83670.68618758966\n",
      "76743.99305149185\n",
      "68010.32594656799\n",
      "0.1304\n",
      "BAF\n",
      "92667.60034827792\n",
      "30101.662312731925\n",
      "84791.58245833017\n",
      "91963.30854806416\n",
      "136175.46403071744\n",
      "98128.49782193999\n",
      "51870.20354750924\n",
      "0.143075\n",
      "BAF\n",
      "45762.39980669247\n",
      "17121.27669126171\n",
      "41313.57558074787\n",
      "35608.02790284081\n",
      "73506.25365048004\n",
      "47481.53092126188\n",
      "30498.503989123856\n",
      "0.14500000000000002\n",
      "BAF\n",
      "92505.83999528631\n",
      "22399.09678951947\n",
      "78582.31338924773\n",
      "100282.98518411847\n",
      "120873.69637101138\n",
      "90696.11904352144\n",
      "71685.6722055352\n",
      "0.1433\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>StDev</th>\n",
       "      <th>1;2</th>\n",
       "      <th>2;1</th>\n",
       "      <th>2;2</th>\n",
       "      <th>2;3</th>\n",
       "      <th>3;2</th>\n",
       "      <th>Group1</th>\n",
       "      <th>Group2</th>\n",
       "      <th>Well</th>\n",
       "      <th>...</th>\n",
       "      <th>Bradford_norm_X</th>\n",
       "      <th>Mean_norm_DMSO</th>\n",
       "      <th>StDev_norm_DMSO</th>\n",
       "      <th>1;2_norm_DMSO</th>\n",
       "      <th>2;1_norm_DMSO</th>\n",
       "      <th>2;2_norm_DMSO</th>\n",
       "      <th>2;3_norm_DMSO</th>\n",
       "      <th>3;2_norm_DMSO</th>\n",
       "      <th>Bradford_norm_DMSO</th>\n",
       "      <th>Try</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36806.6</td>\n",
       "      <td>9522.145205</td>\n",
       "      <td>33569.0</td>\n",
       "      <td>41407.0</td>\n",
       "      <td>51179.0</td>\n",
       "      <td>28358.0</td>\n",
       "      <td>29520.0</td>\n",
       "      <td>X</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.030901</td>\n",
       "      <td>1.444029</td>\n",
       "      <td>2.340499</td>\n",
       "      <td>1.177576</td>\n",
       "      <td>1.749469</td>\n",
       "      <td>2.036702</td>\n",
       "      <td>0.947719</td>\n",
       "      <td>1.261488</td>\n",
       "      <td>1.030901</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35462.4</td>\n",
       "      <td>4664.530019</td>\n",
       "      <td>39797.0</td>\n",
       "      <td>33716.0</td>\n",
       "      <td>30210.0</td>\n",
       "      <td>40921.0</td>\n",
       "      <td>32668.0</td>\n",
       "      <td>X</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>C2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988823</td>\n",
       "      <td>1.422434</td>\n",
       "      <td>1.100751</td>\n",
       "      <td>1.578549</td>\n",
       "      <td>1.341298</td>\n",
       "      <td>0.937903</td>\n",
       "      <td>1.735853</td>\n",
       "      <td>1.558900</td>\n",
       "      <td>0.988823</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19071.8</td>\n",
       "      <td>262.601790</td>\n",
       "      <td>19379.0</td>\n",
       "      <td>18797.0</td>\n",
       "      <td>19252.0</td>\n",
       "      <td>18806.0</td>\n",
       "      <td>19125.0</td>\n",
       "      <td>X</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>C3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986193</td>\n",
       "      <td>0.410934</td>\n",
       "      <td>-0.113252</td>\n",
       "      <td>0.429412</td>\n",
       "      <td>0.406199</td>\n",
       "      <td>0.319250</td>\n",
       "      <td>0.420588</td>\n",
       "      <td>0.511703</td>\n",
       "      <td>0.986193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24196.6</td>\n",
       "      <td>3122.480953</td>\n",
       "      <td>26311.0</td>\n",
       "      <td>20400.0</td>\n",
       "      <td>26177.0</td>\n",
       "      <td>26889.0</td>\n",
       "      <td>21206.0</td>\n",
       "      <td>X</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994083</td>\n",
       "      <td>0.722602</td>\n",
       "      <td>0.672002</td>\n",
       "      <td>0.814463</td>\n",
       "      <td>0.503033</td>\n",
       "      <td>0.706145</td>\n",
       "      <td>0.895840</td>\n",
       "      <td>0.667910</td>\n",
       "      <td>0.994083</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27644.8</td>\n",
       "      <td>3839.420230</td>\n",
       "      <td>29109.0</td>\n",
       "      <td>29416.0</td>\n",
       "      <td>32284.0</td>\n",
       "      <td>22947.0</td>\n",
       "      <td>24468.0</td>\n",
       "      <td>X</td>\n",
       "      <td>CQ</td>\n",
       "      <td>E1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004108</td>\n",
       "      <td>0.963385</td>\n",
       "      <td>0.895480</td>\n",
       "      <td>1.001279</td>\n",
       "      <td>1.098744</td>\n",
       "      <td>1.082014</td>\n",
       "      <td>0.682912</td>\n",
       "      <td>0.947541</td>\n",
       "      <td>0.964278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>23453.8</td>\n",
       "      <td>5589.814997</td>\n",
       "      <td>23442.0</td>\n",
       "      <td>22803.0</td>\n",
       "      <td>30999.0</td>\n",
       "      <td>24700.0</td>\n",
       "      <td>15325.0</td>\n",
       "      <td>FY</td>\n",
       "      <td>CQ</td>\n",
       "      <td>E12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984062</td>\n",
       "      <td>1.234560</td>\n",
       "      <td>1.502508</td>\n",
       "      <td>1.476896</td>\n",
       "      <td>1.113664</td>\n",
       "      <td>1.306049</td>\n",
       "      <td>1.390919</td>\n",
       "      <td>0.821076</td>\n",
       "      <td>1.012561</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>10239.4</td>\n",
       "      <td>1759.222357</td>\n",
       "      <td>8948.0</td>\n",
       "      <td>12481.0</td>\n",
       "      <td>9062.0</td>\n",
       "      <td>8891.0</td>\n",
       "      <td>11815.0</td>\n",
       "      <td>FY</td>\n",
       "      <td>BAF</td>\n",
       "      <td>F9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998203</td>\n",
       "      <td>0.261233</td>\n",
       "      <td>0.338362</td>\n",
       "      <td>0.214932</td>\n",
       "      <td>0.422347</td>\n",
       "      <td>0.057745</td>\n",
       "      <td>0.198092</td>\n",
       "      <td>0.505215</td>\n",
       "      <td>0.969295</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>11460</td>\n",
       "      <td>1406.745890</td>\n",
       "      <td>10888.0</td>\n",
       "      <td>13230.0</td>\n",
       "      <td>9996.0</td>\n",
       "      <td>10526.0</td>\n",
       "      <td>12660.0</td>\n",
       "      <td>FY</td>\n",
       "      <td>BAF</td>\n",
       "      <td>F10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.050665</td>\n",
       "      <td>0.338441</td>\n",
       "      <td>0.213832</td>\n",
       "      <td>0.373061</td>\n",
       "      <td>0.452345</td>\n",
       "      <td>0.107714</td>\n",
       "      <td>0.311506</td>\n",
       "      <td>0.560615</td>\n",
       "      <td>1.020237</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>13424.8</td>\n",
       "      <td>2913.586141</td>\n",
       "      <td>16499.0</td>\n",
       "      <td>16363.0</td>\n",
       "      <td>10987.0</td>\n",
       "      <td>12968.0</td>\n",
       "      <td>10307.0</td>\n",
       "      <td>FY</td>\n",
       "      <td>BAF</td>\n",
       "      <td>F11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.055695</td>\n",
       "      <td>0.481415</td>\n",
       "      <td>0.670760</td>\n",
       "      <td>0.857348</td>\n",
       "      <td>0.662862</td>\n",
       "      <td>0.163012</td>\n",
       "      <td>0.493310</td>\n",
       "      <td>0.334501</td>\n",
       "      <td>1.025122</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>14603.6</td>\n",
       "      <td>3314.616614</td>\n",
       "      <td>17992.0</td>\n",
       "      <td>16758.0</td>\n",
       "      <td>10405.0</td>\n",
       "      <td>16087.0</td>\n",
       "      <td>11776.0</td>\n",
       "      <td>FY</td>\n",
       "      <td>BAF</td>\n",
       "      <td>F12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006109</td>\n",
       "      <td>0.596163</td>\n",
       "      <td>0.831704</td>\n",
       "      <td>1.035311</td>\n",
       "      <td>0.723666</td>\n",
       "      <td>0.136654</td>\n",
       "      <td>0.763263</td>\n",
       "      <td>0.497360</td>\n",
       "      <td>0.976971</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Mean        StDev      1;2      2;1      2;2      2;3      3;2 Group1  \\\n",
       "0    36806.6  9522.145205  33569.0  41407.0  51179.0  28358.0  29520.0      X   \n",
       "1    35462.4  4664.530019  39797.0  33716.0  30210.0  40921.0  32668.0      X   \n",
       "2    19071.8   262.601790  19379.0  18797.0  19252.0  18806.0  19125.0      X   \n",
       "3    24196.6  3122.480953  26311.0  20400.0  26177.0  26889.0  21206.0      X   \n",
       "4    27644.8  3839.420230  29109.0  29416.0  32284.0  22947.0  24468.0      X   \n",
       "..       ...          ...      ...      ...      ...      ...      ...    ...   \n",
       "127  23453.8  5589.814997  23442.0  22803.0  30999.0  24700.0  15325.0     FY   \n",
       "128  10239.4  1759.222357   8948.0  12481.0   9062.0   8891.0  11815.0     FY   \n",
       "129    11460  1406.745890  10888.0  13230.0   9996.0  10526.0  12660.0     FY   \n",
       "130  13424.8  2913.586141  16499.0  16363.0  10987.0  12968.0  10307.0     FY   \n",
       "131  14603.6  3314.616614  17992.0  16758.0  10405.0  16087.0  11776.0     FY   \n",
       "\n",
       "    Group2 Well  ... Bradford_norm_X Mean_norm_DMSO  StDev_norm_DMSO  \\\n",
       "0     DMSO   C1  ...        1.030901       1.444029         2.340499   \n",
       "1     DMSO   C2  ...        0.988823       1.422434         1.100751   \n",
       "2     DMSO   C3  ...        0.986193       0.410934        -0.113252   \n",
       "3     DMSO   C4  ...        0.994083       0.722602         0.672002   \n",
       "4       CQ   E1  ...        1.004108       0.963385         0.895480   \n",
       "..     ...  ...  ...             ...            ...              ...   \n",
       "127     CQ  E12  ...        0.984062       1.234560         1.502508   \n",
       "128    BAF   F9  ...        0.998203       0.261233         0.338362   \n",
       "129    BAF  F10  ...        1.050665       0.338441         0.213832   \n",
       "130    BAF  F11  ...        1.055695       0.481415         0.670760   \n",
       "131    BAF  F12  ...        1.006109       0.596163         0.831704   \n",
       "\n",
       "     1;2_norm_DMSO  2;1_norm_DMSO  2;2_norm_DMSO  2;3_norm_DMSO  \\\n",
       "0         1.177576       1.749469       2.036702       0.947719   \n",
       "1         1.578549       1.341298       0.937903       1.735853   \n",
       "2         0.429412       0.406199       0.319250       0.420588   \n",
       "3         0.814463       0.503033       0.706145       0.895840   \n",
       "4         1.001279       1.098744       1.082014       0.682912   \n",
       "..             ...            ...            ...            ...   \n",
       "127       1.476896       1.113664       1.306049       1.390919   \n",
       "128       0.214932       0.422347       0.057745       0.198092   \n",
       "129       0.373061       0.452345       0.107714       0.311506   \n",
       "130       0.857348       0.662862       0.163012       0.493310   \n",
       "131       1.035311       0.723666       0.136654       0.763263   \n",
       "\n",
       "     3;2_norm_DMSO  Bradford_norm_DMSO  Try  \n",
       "0         1.261488            1.030901    1  \n",
       "1         1.558900            0.988823    1  \n",
       "2         0.511703            0.986193    1  \n",
       "3         0.667910            0.994083    1  \n",
       "4         0.947541            0.964278    1  \n",
       "..             ...                 ...  ...  \n",
       "127       0.821076            1.012561    4  \n",
       "128       0.505215            0.969295    4  \n",
       "129       0.560615            1.020237    4  \n",
       "130       0.334501            1.025122    4  \n",
       "131       0.497360            0.976971    4  \n",
       "\n",
       "[132 rows x 45 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pathophys as pp\n",
    "spec = \"5\"\n",
    "df = pp.get_df_flourometry(spec, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92b2cb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DMSO\n",
      "CQ\n",
      "X\n",
      "TP\n",
      "FY\n",
      "BAF\n",
      "X\n",
      "TP\n",
      "FY\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.transforms as transforms\n",
    "\n",
    "\n",
    "def lineplot_F(df, x, y,z):\n",
    "    form = {\"X\":\"-s\",\"TP\":\"-D\",\"FY\":\"-o\"}\n",
    "    for xl in df[x].unique():\n",
    "        print(xl)\n",
    "        if xl == \"DMSO\":\n",
    "            continue\n",
    "        for zl in df[z].unique():\n",
    "            print(zl)\n",
    "            X = [\"DMSO\",xl]\n",
    "            Y = [df[y][df[x]==\"DMSO\"][df[z]==zl].median(),df[y][df[x]==xl][df[z]==zl].median()]\n",
    "            plt.plot(X,Y,form[zl],scaley = False)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "lineplot_F(df, \"Group2\", \"Mean_norm_X\",\"Group1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
